{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85da2a06-e769-480b-92f0-285bf89b0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MRI Brain Tumor Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd1c4b-1ce5-4747-bc1f-413860e01584",
   "metadata": {},
   "source": [
    "link: https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df54cc4e-2698-43d0-a486-154fbdf4311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985cea1f-8afc-4d84-9f55-ab19f3da1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b73437a-7782-43fa-9f06-867b708b0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading MRI Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72846537-8615-4458-87a8-5520c48e7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant = []\n",
    "benign = []\n",
    "for f in glob.iglob(\"./brain_tumor_dataset/yes/*.[jJ][pP][gG]\"):\n",
    "    img = cv2.imread(f)\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    b, g, r = cv2.split(img)\n",
    "    img = cv2.merge([r,g,b])\n",
    "    malignant.append(img)\n",
    "\n",
    "for f in glob.iglob(\"./brain_tumor_dataset/no/*.[jJ][pP][gG]\"):\n",
    "    img = cv2.imread(f)\n",
    "    img = cv2.resize(img,(128,128)) \n",
    "    b, g, r = cv2.split(img)\n",
    "    img = cv2.merge([r,g,b])\n",
    "    benign.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b1448e-f2e3-4ef1-b48a-3bd7a1a37e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant = np.array(malignant)\n",
    "benign = np.array(benign)\n",
    "combined = np.concatenate((benign, malignant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e9d583-6890-4a7d-ad2b-dfa5d4b62602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 128, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malignant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44f91bf-0510-4fd9-8ca4-7f1f94f99a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 128, 128, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d120f5-6f37-43cf-bfa7-56323ff37c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 7, 4, 3, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(10, 5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc742906-80a4-4e8f-8745-bd99cc42dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing MRI Images (Images shown below are not trained, so they are not accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2efa92-407c-4d2e-9dc5-57e011555bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(benign, malignant, cols=5):\n",
    "    def plot_category(images, title):\n",
    "        num_images = len(images)\n",
    "        rows = (num_images + cols - 1) // cols\n",
    "\n",
    "        plt.figure(figsize=(16, 2 * rows)) \n",
    "        for i, img in enumerate(images, 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.imshow(img)\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot benign images\n",
    "    plot_category(benign, \"Safe\")\n",
    "\n",
    "    # Plot malignant images\n",
    "    plot_category(malignant, \"Tumor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72199d9-72b1-41e5-a447-aa6c62a1dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(benign, malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244979c-c47f-4933-8ecf-d7a402f42333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch's Abstract Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7970f37-8cc9-4bbe-9fe0-bde586f79dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "\n",
    "    All other datasets should subclass it. All subclasses should override\n",
    "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
    "    supporting integer indexing in range from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d450d-1624-496e-ae56-d4ccecf4b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128)\n",
    "\n",
    "def load_and_process_image(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.resize(img, IMAGE_SIZE)\n",
    "        b, g, r = cv2.split(img)\n",
    "        img = cv2.merge([r, g, b])\n",
    "        img = img.reshape((img.shape[2], img.shape[0], img.shape[1]))\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "class MRI(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for MRI images.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        tumor = [load_and_process_image(f) for f in glob.iglob(\"./data/brain_tumor_dataset/yes/*.[jJ][pP][gG]\")]\n",
    "        safe = [load_and_process_image(f) for f in glob.iglob(\"./data/brain_tumor_dataset/no/*.[jJ][pP][gG]\")]\n",
    "        \n",
    "        tumor = np.array([img for img in tumor if img is not None], dtype=np.float32)\n",
    "        safe = np.array([img for img in safe if img is not None], dtype=np.float32)\n",
    "        \n",
    "        tumor_label = np.ones(tumor.shape[0], dtype=np.float32)\n",
    "        safe_label = np.zeros(safe.shape[0], dtype=np.float32)\n",
    "        \n",
    "        self.images = np.concatenate((tumor, safe), axis=0)\n",
    "        self.labels = np.concatenate((tumor_label, safe_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = {'image': self.images[index], 'label': self.labels[index]}\n",
    "        return sample\n",
    "    \n",
    "    def normalize(self):\n",
    "        self.images = self.images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad88a6-6d9e-436d-8fe5-0cc2f2386867",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dataset = MRI()\n",
    "mri_dataset.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af93a4-e994-4260-8e45-cbd2af4f435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb7104-5ac7-49af-8e74-aa853ecfd8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {0: 'Safe', 1: 'Tumor'}\n",
    "dataloader = DataLoader(mri_dataset, shuffle=True)\n",
    "\n",
    "for i, sample in enumerate(dataloader):\n",
    "    img = sample['image'].squeeze()\n",
    "    img = img.reshape((img.shape[1], img.shape[2], img.shape[0]))\n",
    "    plt.title(names[sample['label'].item()])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83d014-8db7-49ad-bf70-829a19931ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fa90d-934b-4d11-a22e-896e04efb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "        nn.Tanh(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=5),\n",
    "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "        nn.Tanh(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=5))\n",
    "        \n",
    "        self.fc_model = nn.Sequential(\n",
    "        nn.Linear(in_features=256, out_features=120),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=120, out_features=84),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=84, out_features=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_model(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b36b2b-7461-4ac1-9d15-cb4230d5b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e14b1-16c4-4858-9b08-f2d8d2bb63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63157ff5-3da1-45be-9e11-cf5a3ce7153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cnn_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5293d55-335b-418f-84b9-6605b6c6a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cnn_model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e450d-fe17-443a-bd50-b91ec6f68f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cnn_model[0].weight[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7d4c5-af11-415c-946a-d5e91b0b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d45e1-3caf-46a8-bca7-45bf1a287b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9c9e5-98b9-42c9-a7fd-d2f1572b212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce22e80-841b-4eba-acd9-7d2260eb668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c27b4-75d2-49c0-8450-1f9cf31a0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc_model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadc4c7-d1cb-4c9e-bcf6-1d7b2dafad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating a New Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df06755-809e-43c2-b979-d2710112fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dataset = MRI()\n",
    "mri_dataset.normalize()\n",
    "model = CNN()\n",
    "\n",
    "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4d69e-ed4b-4651-9251-ace6f78d0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=False)\n",
    "outputs=[]\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for D in dataloader:\n",
    "        image =  D['image']\n",
    "        label = D['label']\n",
    "        \n",
    "        y_hat = model(image)\n",
    "        \n",
    "        outputs.append(y_hat.cpu().detach().numpy())\n",
    "        y_true.append(label.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d251ece-07dd-4f48-9868-abec86c4b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.concatenate( outputs, axis=0 ).squeeze()\n",
    "y_true = np.concatenate( y_true, axis=0 ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fc50e-cd1e-4dd2-841b-21abba79afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(scores,threshold=0.50, minimum=0, maximum = 1.0):\n",
    "    x = np.array(list(scores))\n",
    "    x[x >= threshold] = maximum\n",
    "    x[x < threshold] = minimum\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbe685-6865-4ffc-bf79-e1bb684d303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132e1d-9630-4801-85f3-6b824cc3010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.0001\n",
    "EPOCH = 400\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9a99e-75b8-4787-9888-5b2427f3c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCH):\n",
    "    losses = []\n",
    "    for D in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        data = D['image']\n",
    "        label = D['label']\n",
    "        y_hat = model(data)\n",
    "        error = nn.BCELoss() \n",
    "        loss = torch.sum(error(y_hat.squeeze(), label))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699299c0-8c3f-4019-958b-205bd550cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70017ed-9161-494e-a3b5-f9d4e318dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=False)\n",
    "outputs=[]\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for D in dataloader:\n",
    "        image =  D['image']\n",
    "        label = D['label']\n",
    "        \n",
    "        y_hat = model(image)\n",
    "        \n",
    "        outputs.append(y_hat.cpu().detach().numpy())\n",
    "        y_true.append(label.cpu().detach().numpy())\n",
    "        \n",
    "outputs = np.concatenate( outputs, axis=0 )\n",
    "y_true = np.concatenate( y_true, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bc721-8057-4a08-86f2-2eb24be00b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, threshold(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf173941-21cc-4500-bffb-41ade1dcac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d9457-6dfb-41ec-a0db-cf2522474f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, threshold(outputs))\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['malignant','Benign'])\n",
    "ax.yaxis.set_ticklabels(['malignant','Benign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ee7de-9abc-4cfe-93c7-225d4ab953a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(outputs)\n",
    "plt.axvline(x=len(malignant), color='r', linestyle='--')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ce4c2-7d2e-437a-a247-ebd55f4000ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing MRI Images with accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288cbb1-8fad-4f43-818c-569e048fad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(benign, malignant, cols=5):\n",
    "    def plot_category(images, title):\n",
    "        num_images = len(images)\n",
    "        rows = (num_images + cols - 1) // cols\n",
    "\n",
    "        plt.figure(figsize=(16, 2 * rows)) \n",
    "        for i, img in enumerate(images, 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.imshow(img)\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot benign images\n",
    "    plot_category(benign, \"Safe\")\n",
    "\n",
    "    # Plot malignant images\n",
    "    plot_category(malignant, \"Tumor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97246fe6-9eef-42f2-9c12-3f53fd4892d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(benign, malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8f34c-598e-4072-b657-703016adf609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}




